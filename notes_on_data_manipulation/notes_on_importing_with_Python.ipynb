{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. flat files\n",
    "\n",
    "### text files .txt - containing plain text\n",
    "\n",
    "basic text files containing records, that is, table data, without structured relationships.\n",
    "record == row of fields or attributes, each of which contains at most one item of information. \n",
    "\n",
    "```\n",
    "filename = 'plaintextfile.txt'\n",
    "file = open(filename, mode='r') # 'r' is to read, to write pass 'w'...\n",
    "text = file.read() # this contains the whole text\n",
    "file.close()\n",
    "```\n",
    "\n",
    "* You can avoid having to close the connection to the file by using a context manager \n",
    "\n",
    "```\n",
    "with open('plaintextfile.txt') as file:\n",
    "    print(file.readline())\n",
    "```\n",
    "\n",
    "### files .csv - comma separated value\n",
    "\n",
    "Values in flat files can be separated by characters or sequences of characters other than commas, such as a tab, and the character or characters in question is called a delimiter.\n",
    "\n",
    "\n",
    "# 2. files native to specific software\n",
    "\n",
    "### Pickled files\n",
    "\n",
    "This is a file type native to Python. \n",
    "While it may be easy to save a numpy array or a pandas dataframe to a flat file, there are many other datatypes, such as dictionaries and lists, for which it isn't obvious how to store them. If you only want to be able to import them into Python, you can serialize them. All this means is converting the object into a sequence of bytes, or bytestream non human-readable)\n",
    "\n",
    "```\n",
    "import pickle\n",
    "with open('pickled_file.pkl', 'rb') as file:    #'rb' to specify both readable and binary\n",
    "data = pickle.load(file)\n",
    "print(data)\n",
    "```\n",
    "\n",
    "### Excel spreadsheets\n",
    "\n",
    "better with pandas\n",
    "\n",
    "### Stata\n",
    "\n",
    "* Stata: “Statistics” + “data”\n",
    "* academic social sciences research\n",
    "\n",
    "### SAS\n",
    "\n",
    "* SAS: Statistical Analysis System\n",
    "* business analytics and biostatistics\n",
    "\n",
    "### HDF5 files\n",
    "Hierarchical Data Format version 5\n",
    "Standard for storing large quantities of numerical data\n",
    "Datasets can be hundreds of gigabytes or terabytes\n",
    "HDF5 can scale to exabytes\n",
    "\n",
    "```\n",
    "import h5py\n",
    "filename = 'hdf5file.hdf5'\n",
    "data = h5py.File(filename, 'r') # 'r' is to read\n",
    "print(data.keys())\n",
    "print(data['key1'].keys()\n",
    "```\n",
    "\n",
    "### MATLAB \n",
    "\n",
    "* “Matrix Laboratory”\n",
    "* Industry standard in engineering and science\n",
    "* Data saved as `.mat` files\n",
    "\n",
    "# 3.  relational databases \n",
    "\n",
    "### SQLite and PostgreSQL\n",
    "\n",
    "```\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('sqlite:///databasename.sqlite')\n",
    "table_names = engine.table_names()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing files in numpy\n",
    "\n",
    "### `loadtxt()` is great for basic cases, same datatypes in flat file\n",
    "\n",
    "* the default `delimiter` is any white space\n",
    "\n",
    "```\n",
    "import numpy as np\n",
    "filename = 'plain.txt'\n",
    "data = np.loadtxt(filename, delimiter=',', skiprows=1, , usecols=[0, 2], dtype=str)\n",
    "data2 = np.loadtxt(file, delimiter='\\t', skiprows=2, usecols=[1,2])\n",
    "```\n",
    "\n",
    "### `genfromtxt()` can handle mixed datatypes in flat files\n",
    "\n",
    "```\n",
    "data = np.genfromtxt('plain.csv', delimiter=',', names=True, dtype=None)\n",
    "```\n",
    "* the third argument names tells us there is a header. \n",
    "\n",
    "data is an object called a **structured array**, as the data are of different types, and numpy arrays have to contain elements that are all the same type. \n",
    "The structured array solves this by being a 1D array, where each element of the array is a row of the flat file imported. \n",
    "You can test this by checking out the array's shape in the shell by executing np.shape(data)\n",
    "\n",
    "### `recfromcsv()` \n",
    "\n",
    "behaves similarly to `np.genfromtxt()`, except that its default `dtype` is `None`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing files in pandas\n",
    "\n",
    "```\n",
    "import pandas as pd\n",
    "\n",
    "# Assign the filename: file\n",
    "file = 'plain.csv'\n",
    "\n",
    "# Read the file into a DataFrame: df\n",
    "df = pd.read_csv(file, nrows=5, header=None, names=[a,b,c], index_col=0, , sep='\\t', comment='#', na_values='Nothing')\n",
    "```\n",
    "\n",
    "### excel\n",
    "\n",
    "```\n",
    "import pandas as pd\n",
    "file = 'ex.xlsx'\n",
    "data = pd.ExcelFile(file)\n",
    "print(data.sheet_names)\n",
    "df1 = data.parse('tree', skiprows=[0], names=['a' , 'b']) # sheet name, as a string\n",
    "df2 = data.parse(0,usecols=[0], skiprows=[0], names=['zzz']) # sheet index, as a float\n",
    "```\n",
    "* pd.read_excel() defaults to sheet 0\n",
    "* passig sheet_name=None we get a Dict whose keys are the sheets\n",
    "```\n",
    "df  = pd.read_excel(file, sheet_name='flaksjdhf')\n",
    "df4 = pd.read_excel(open('ex.xlsx', 'rb'), dtype={'Name': str, 'Value': float}, na_values=['string1', 'string2'])\n",
    "```\n",
    "\n",
    "### SAS\n",
    "\n",
    "```\n",
    "import pandas as pd\n",
    "from sas7bdat import SAS7BDAT\n",
    "with SAS7BDAT('sasfile.sas7bdat') as file:\n",
    "df_sas = file.to_data_frame()\n",
    "```\n",
    "\n",
    "### Stata\n",
    "\n",
    "```\n",
    "import pandas as pd\n",
    "data = pd.read_stata('statafile.dta')\n",
    "```\n",
    "\n",
    "### SQLite\n",
    "\n",
    "```\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd \n",
    "engine = create_engine('sqlite:///dbname.sqlite')\n",
    "con = engine.connect()\n",
    "rs = con.execute(\"SELECT * FROM table\")\n",
    "df = pd.DataFrame(rs.fetchall())\n",
    "df.columns = rs.keys()\n",
    "con.close()\n",
    "```\n",
    "* context manager\n",
    "```\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "engine = create_engine('sqlite:///dbname.sqlite')\n",
    "with engine.connect() as con:\n",
    "    rs = con.execute(\"SELECT col1, col2 FROM table\")\n",
    "    df = pd.DataFrame(rs.fetchmany(size=5))\n",
    "    df.columns = rs.keys()\n",
    "```\n",
    "\n",
    "```\n",
    "df = pd.read_sql_query(\"SELECT * FROM table\", engine)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# in scipy\n",
    "\n",
    "### MATLAB files\n",
    "`scipy.io.loadmat()` - load `.mat` files as a dict where \n",
    "keys = MATLAB variable names\n",
    "values = objects assigned to variables (like numpy arrays)\n",
    "`scipy.io.savemat()` - write `.mat` files"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
